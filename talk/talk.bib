@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@techreport{renyi1961measures,
  title={On measures of entropy and information},
  author={R{\'{e}}nyi, Alfr{\'{e}}d},
  year={1961},
  institution={HUNGARIAN ACADEMY OF SCIENCES Budapest Hungary}
}

@inproceedings{cortes2010learning,
  title={Learning bounds for importance weighting},
  author={Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
  booktitle={Advances in neural information processing systems},
  pages={442--450},
  year={2010}
}

@article{amari2010information,
  title={Information geometry of divergence functions},
  author={Amari, Shun-ichi and Cichocki, Andrzej},
  journal={Bulletin of the Polish Academy of Sciences: Technical Sciences},
  volume={58},
  number={1},
  pages={183--195},
  year={2010},
  publisher={Versita}
}

@inproceedings{sehnke2008policy,
	title={Policy gradients with parameter-based exploration for control},
	author={Sehnke, Frank and Osendorfer, Christian and R{\"u}ckstie{\ss}, Thomas and Graves, Alex and Peters, Jan and Schmidhuber, J{\"u}rgen},
	booktitle={International Conference on Artificial Neural Networks},
	pages={387--396},
	year={2008},
	organization={Springer}
}

@inproceedings{wierstra2008natural,
	title={Natural evolution strategies},
	author={Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, Juergen},
	booktitle={Evolutionary Computation, 2008. CEC 2008.(IEEE World Congress on Computational Intelligence). IEEE Congress on},
	pages={3381--3387},
	year={2008},
	organization={IEEE}
}

@article{sehnke2010parameter,
	title={Parameter-exploring policy gradients},
	author={Sehnke, Frank and Osendorfer, Christian and R{\"u}ckstie{\ss}, Thomas and Graves, Alex and Peters, Jan and Schmidhuber, J{\"u}rgen},
	journal={Neural Networks},
	volume={23},
	number={4},
	pages={551--559},
	year={2010},
	publisher={Elsevier}
}

@article{zhao2013efficient,
	title={Efficient sample reuse in policy gradients with parameter-based exploration},
	author={Zhao, Tingting and Hachiya, Hirotaka and Tangkaratt, Voot and Morimoto, Jun and Sugiyama, Masashi},
	journal={Neural computation},
	volume={25},
	number={6},
	pages={1512--1547},
	year={2013},
	publisher={MIT Press}
}

@inproceedings{miyamae2010natural,
	title={Natural policy gradient methods with parameter-based exploration for control tasks},
	author={Miyamae, Atsushi and Nagata, Yuichi and Ono, Isao and Kobayashi, Shigenobu},
	booktitle={Advances in neural information processing systems},
	pages={1660--1668},
	year={2010}
}

@article{gruttnermulti,
	title={Multi-Dimensional Deep Memory Go-Player for Parameter Exploring Policy Gradients},
	author={Gr{\"u}ttner, Mandy and Sehnke, Frank and Schaul, Tom and Schmidhuber, J{\"u}rgen}
}

@inproceedings{thomas2015high,
  title={High-Confidence Off-Policy Evaluation.},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={AAAI},
  pages={3000--3006},
  year={2015}
}

@inproceedings{thomas2015high2,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}

@book{mcbook,
   author = {Art B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and Trends in Robotics},
  volume={2},
  number={1--2},
  pages={1--142},
  year={2013},
  publisher={Now Publishers, Inc.}
}

@article{van2014renyi,
  title={R{\'{e}}nyi divergence and Kullback-Leibler divergence},
  author={Van Erven, Tim and Harremos, Peter},
  journal={IEEE Transactions on Information Theory},
  volume={60},
  number={7},
  pages={3797--3820},
  year={2014},
  publisher={IEEE}
}

@book{cochran2007sampling,
  title={Sampling techniques},
  author={Cochran, William G},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{kong1992note,
  title={A note on importance sampling using standardized weights},
  author={Kong, Augustine},
  journal={University of Chicago, Dept. of Statistics, Tech. Rep},
  volume={348},
  year={1992}
}

@article{martino2017effective,
  title={Effective sample size for importance sampling based on discrepancy measures},
  author={Martino, Luca and Elvira, V{\'{i}}ctor and Louzada, Francisco},
  journal={Signal Processing},
  volume={131},
  pages={386--401},
  year={2017},
  publisher={Elsevier}
}

@article{bernstein1924modification,
  title={On a modification of Chebyshevâ€™s inequality and of the error formula of Laplace},
  author={Bernstein, Sergei},
  journal={Ann. Sci. Inst. Sav. Ukraine, Sect. Math},
  volume={1},
  number={4},
  pages={38--49},
  year={1924}
}

@article{hoeffding1963probability,
  title={Probability inequalities for sums of bounded random variables},
  author={Hoeffding, Wassily},
  journal={Journal of the American statistical association},
  volume={58},
  number={301},
  pages={13--30},
  year={1963},
  publisher={Taylor \& Francis Group}
}

@article{maurer2009empirical,
  title={Empirical Bernstein bounds and sample variance penalization},
  author={Maurer, Andreas and Pontil, Massimiliano},
  journal={arXiv preprint arXiv:0907.3740},
  year={2009}
}

@incollection{rao1992information,
	title={Information and the accuracy attainable in the estimation of statistical parameters},
	author={Rao, C Radhakrishna},
	booktitle={Breakthroughs in statistics},
	pages={235--247},
	year={1992},
	publisher={Springer}
}

@book{amari2012differential,
	title={Differential-geometrical methods in statistics},
	author={Amari, Shun-ichi},
	volume={28},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@article{amari1998natural,
	title={Natural gradient works efficiently in learning},
	author={Amari, Shun-Ichi},
	journal={Neural computation},
	volume={10},
	number={2},
	pages={251--276},
	year={1998},
	publisher={MIT Press}
}

@inproceedings{kakade2002natural,
	title={A natural policy gradient},
	author={Kakade, Sham M},
	booktitle={Advances in neural information processing systems},
	pages={1531--1538},
	year={2002}
}

@article{ver2012invented,
  title={Who invented the delta method?},
  author={Ver Hoef, Jay M},
  journal={The American Statistician},
  volume={66},
  number={2},
  pages={124--127},
  year={2012},
  publisher={Taylor \& Francis}
}

@phdthesis{hesterberg1988advances,
  title={Advances in importance sampling},
  author={Hesterberg, Timothy Classen},
  year={1988},
  school={Stanford University}
}

@inproceedings{cantelli1929sui,
  title={Sui confini della probabilita},
  author={Cantelli, FP},
  booktitle={Atti del Congresso Internazionale dei Matematici: Bologna del 3 al 10 de settembre di 1928},
  pages={47--60},
  year={1929}
}

@inproceedings{matsubara2010adaptive,
  title={Adaptive step-size policy gradients with average reward metric},
  author={Matsubara, Takamitsu and Morimura, Tetsuro and Morimoto, Jun},
  booktitle={Proceedings of 2nd Asian Conference on Machine Learning},
  pages={285--298},
  year={2010}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{rajeswaran2017towards,
  title={Towards generalization and simplicity in continuous control},
  author={Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel V and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6553--6564},
  year={2017}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@article{baxter2001infinite,
  title={Infinite-horizon policy-gradient estimation},
  author={Baxter, Jonathan and Bartlett, Peter L},
  journal={Journal of Artificial Intelligence Research},
  volume={15},
  pages={319--350},
  year={2001}
}

@incollection{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  booktitle={Reinforcement Learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{kurutach2018model,
  title={Model-ensemble trust-region policy optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1802.10592},
  year={2018}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume={2},
  pages={267--274},
  year={2002}
}

@inproceedings{pirotta2013safe,
  title={Safe policy iteration},
  author={Pirotta, Matteo and Restelli, Marcello and Pecorino, Alessio and Calandriello, Daniele},
  booktitle={International Conference on Machine Learning},
  pages={307--315},
  year={2013}
}

@article{burbea1984convexity,
  title={The convexity with respect to Gaussian distributions of divergences of order $\alpha$},
  author={Burbea, Jacob},
  journal={Utilitas Mathematica},
  volume={26},
  pages={171--192},
  year={1984},
  publisher={Utilitas Mathematica Publishing Inc.}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'{e}}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@incollection{peng1994incremental,
  title={Incremental multi-step Q-learning},
  author={Peng, Jing and Williams, Ronald J},
  booktitle={Machine Learning Proceedings 1994},
  pages={226--232},
  year={1994},
  publisher={Elsevier}
}

@article{wright1999numerical,
  title={Numerical optimization},
  author={Wright, Stephen and Nocedal, Jorge},
  journal={Springer Science},
  volume={35},
  number={67-68},
  pages={7},
  year={1999}
}

@inproceedings{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  pages={5285--5294},
  year={2017}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{doroudi2017importance,
  title={Importance sampling for fair policy selection},
  author={Doroudi, Shayan and Thomas, Philip S and Brunskill, Emma},
  year={2017},
  organization={UAI}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{guo2017using,
  title={Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation},
  author={Guo, Zhaohan and Thomas, Philip S and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2489--2498},
  year={2017}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{ng2000pegasus,
  title={PEGASUS: A policy search method for large MDPs and POMDPs},
  author={Ng, Andrew Y and Jordan, Michael},
  booktitle={Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence},
  pages={406--415},
  year={2000},
  organization={Morgan Kaufmann Publishers Inc.}
}

@inproceedings{tedrake2004stochastic,
  title={Stochastic policy gradient reinforcement learning on a simple 3D biped},
  author={Tedrake, Russ and Zhang, Teresa Weirui and Seung, H Sebastian},
  booktitle={Intelligent Robots and Systems, 2004.(IROS 2004). Proceedings. 2004 IEEE/RSJ International Conference on},
  volume={3},
  pages={2849--2854},
  year={2004},
  organization={IEEE}
}

@article{hansen2001completely,
  title={Completely derandomized self-adaptation in evolution strategies},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary computation},
  volume={9},
  number={2},
  pages={159--195},
  year={2001},
  publisher={MIT Press}
}

@article{szita2006learning,
  title={Learning Tetris using the noisy cross-entropy method},
  author={Szita, Istv{\'{a}}n and L{\"o}rincz, Andr{\'{a}}s},
  journal={Neural computation},
  volume={18},
  number={12},
  pages={2936--2941},
  year={2006},
  publisher={MIT Press}
}

@article{rubinstein1999cross,
  title={The cross-entropy method for combinatorial and continuous optimization},
  author={Rubinstein, Reuven},
  journal={Methodology and computing in applied probability},
  volume={1},
  number={2},
  pages={127--190},
  year={1999},
  publisher={Springer}
}

@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@article{tucker2018mirage,
  title={The Mirage of Action-Dependent Baselines in Reinforcement Learning},
  author={Tucker, George and Bhupatiraju, Surya and Gu, Shixiang and Turner, Richard E and Ghahramani, Zoubin and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.10031},
  year={2018}
}

@article{wu2018variance,
  title={Variance reduction for policy gradient with action-dependent factorized baselines},
  author={Wu, Cathy and Rajeswaran, Aravind and Duan, Yan and Kumar, Vikash and Bayen, Alexandre M and Kakade, Sham and Mordatch, Igor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1803.07246},
  year={2018}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@inproceedings{zhao2011analysis,
  title={Analysis and improvement of policy gradient estimation},
  author={Zhao, Tingting and Hachiya, Hirotaka and Niu, Gang and Sugiyama, Masashi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={262--270},
  year={2011}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@inproceedings{precup2000eligibility,
  title={Eligibility Traces for Off-Policy Policy Evaluation.},
  author={Precup, Doina and Sutton, Richard S and Singh, Satinder P},
  booktitle={ICML},
  pages={759--766},
  year={2000},
  organization={Citeseer}
}

@inproceedings{peters2010relative,
  title={Relative Entropy Policy Search.},
  author={Peters, Jan and M{\"u}lling, Katharina and Altun, Yasemin},
  booktitle={AAAI},
  pages={1607--1612},
  year={2010},
  organization={Atlanta}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007},
  organization={ACM}
}

@inproceedings{sun2009efficient,
  title={Efficient natural evolution strategies},
  author={Sun, Yi and Wierstra, Daan and Schaul, Tom and Schmidhuber, Juergen},
  booktitle={Proceedings of the 11th Annual conference on Genetic and evolutionary computation},
  pages={539--546},
  year={2009},
  organization={ACM}
}

@misc{bernstein1927theory,
  title={Theory of probability},
  author={Bernstein, S},
  year={1927},
  publisher={Moscow}
}

@incollection{bercu2015concentration,
  title={Concentration inequalities for sums},
  author={Bercu, Bernard and Delyon, Bernard and Rio, Emmanuel},
  booktitle={Concentration Inequalities for Sums and Martingales},
  pages={11--60},
  year={2015},
  publisher={Springer}
}

@inproceedings{kober2011reinforcement,
  title={Reinforcement learning to adjust robot movements to new situations},
  author={Kober, Jens and {\"O}ztop, Erhan and Peters, Jan},
  booktitle={IJCAI Proceedings-International Joint Conference on Artificial Intelligence},
  volume={22},
  number={3},
  pages={2650},
  year={2011}
}

@article{dayan1997using,
  title={Using expectation-maximization for reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Neural Computation},
  volume={9},
  number={2},
  pages={271--278},
  year={1997},
  publisher={MIT Press}
}